{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font face=\"arial\" size=\"5\" color=#0101DF>NUMERIQUE ET SCIENCES INFORMATIQUES Terminale NSI</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=#013ADF>Séquence N° 4 : Projet \"Compression selon la méthode de HUFMANN\"</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a et on aura toujours besoin de compresser les données, la réduction de la taille des fichiers facilitant leur stockage, leur transfert sur un réseau.\n",
    "Plusieurs techniques sont utilisées, certaines avec pertes, d'autres sans pertes. N'hésitez pas à vous informer sur ces techniques pour votre culture personnelle.\n",
    "\n",
    "Vous allez ici implémenter l'agorithme de compression sans perte de **David Albert Huffman**, qui l'a publié en 1952. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le principe est coder un motif (ici des caractères) sur un nombre variable de bits, en utilisant peu de bits pour les caractères fréquents et plus de bits pour les caractères rares. Ce codage dépend donc du fichier à compresser. \n",
    "Les propriétés d'un tel codage doivent être les suivantes :\n",
    "\n",
    "- Chaque caractère est codé sur un nombre différent de bits ;\n",
    "- Les codes des caractères fréquents dans le fichier sont courts, ceux des caractères rares sont plus longs. Il utilise la notion de **code préfixe** ;\n",
    "\n",
    "code préfixe : https://fr.wikipedia.org/wiki/Code_pr%C3%A9fixe\n",
    "- Bien que les codes soient de longueur variable, on peut décoder le fichier compressé de façon unique.\n",
    "\n",
    "En effet, lorsqu'on décode le fichier compressé en le lisant linéairement, dès que l'on reconnaît le code d'un caractère, on sait que l'on ne pourra pas le compléter en un autre code.\n",
    "\n",
    "L'algorithme de Huffman, qui garantit ces propriétés, fonctionne de la façon suivante :\n",
    "- On calcule d'abord les fréquences d'apparition de chaque caractère dans le fichier à compresser ;\n",
    "- On calcule ensuite pour chaque caractère un code satisfaisant les propriétés énoncées précédemment ;\n",
    "- On écrit ce code au début du fichier compressé (pour que le décompresseur y ait accès),suivi des données compressées elles-mêmes.\n",
    "\n",
    "Pour calculer le code de chaque caractère, l'algorithme construit un arbre binaire par itérations :\n",
    "- Les feuilles de l'arbre sont les caractères apparaissant dans le fichier ;\n",
    "- Deux nœuds n1 et n2 de fréquences minimales sont choisis. On construit un nouveau nœud n qui devient :\n",
    "    - père de n1 et n2, et dont la fréquence est la somme de celles de n1 et n2 ;\n",
    "    - On répète l'étape précédente jusqu'à atteindre une unique racine.\n",
    "    \n",
    "Vous pouvez visualiser le processus en suivant le lien suivant : http://lwh.free.fr/pages/algo/compression/huffman.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si dans l'animation utilisée, vous saisissez le texte : \"abracadabra\", vous devriez obtenir un graphe ressemblant à celui ci-dessous.\n",
    "\n",
    "On constate que la taille du texte qui contient 11 caractères est en bits est de 11 x 8 bits = 88 bits.\n",
    "\n",
    "La compression a affecté aux caractères, les codes suivants :\n",
    "\n",
    "a : 0\n",
    "r : 10\n",
    "b : 111\n",
    "c : 1100\n",
    "d : 1101\n",
    "\n",
    "La lecture du code se fait en parcourant le graphe en profondeur (voir ci-dessous).\n",
    "\n",
    "Pour 5 x a : 5 bits, 2 x r : 4 bits, 2 x b : 6 bits, 1 x c : 4 bits et 1 x d : 4 bits, soit un total de 23 bits que voici : 01111001100011010111100\n",
    "\n",
    "Le taux de compression est de 26 % environ.\n",
    "\n",
    "Lors de l'interprétation du message binaire :\n",
    "- Le message commence par 0, ce ne peut être qu'un \"a\" ;\n",
    "- Une serie de 1, 4 \"1\" successifs n'existe pas, donc c'est \"b\" avec le code \"111\" ;\n",
    "- Un mot \"100...\" n'existe pas, c'est donc le \"r\" avec le code \"10\" ;\n",
    "- Le code \"01...\" n'existe pas, il s'agit donc d'un \"a\" ;\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"Images/abracadabra.png\" alt=\"Huffman\" width=40% align=center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travail demandé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- On vous demande d'implémenter l'algorithme de HUFFMAN semi-adaptatif en suivant les contraintes ci-dessous. Dans sa version finale, l'application devra :\n",
    "\n",
    "- Lire le texte à compresser dans un fichier ;\n",
    "- Les caractères utilisés dans le message et leur fréquence d'apparition seront stockés dans un dictionnaire ;\n",
    "- L'ensemble des caractères et leur code binaire associés seront stockés dans un dictionnaire ;\n",
    "- Le texte compressé et son dictionnaire de décodage dans un fichier texte.\n",
    "\n",
    "Voici quelques pistes de travail :\n",
    "- On créera une classe **Noeud**. Vous serez amener à définir le comportement de la méthode spéciale `__lt__` afin de pouvoir comparer la fréquence de 2 objets de type Noeud lors de la construction de l'arbre ;\n",
    "- Pour distinguer les feuilles et les noeuds internes de l'arbre, il faudra nommer les noeuds internes.\n",
    "- Pour construire l'arbre, on utilisera la notion de **tas (heap)**, on importera le module **heapq** dont vous avez une démonstration ci-dessous (avec le lien vers la documentation);\n",
    "- Pour pouvoir réaliser la décompression (semi-adaptatif), il nous faut le dictionnaire des codes affectés aux caractères. On peut imaginer sérialiser le dictionnaire (voir ci-dessous) et le placer dans le fichier compressé sauvegardé, sans le compresser lui-même.\n",
    "\n",
    "2- Fatalement, il faut réaliser l'application inverse qui après lecture du fichier compressé et du dictionnaire de décodage, va restituer le message en clair.\n",
    "\n",
    "*Remarques : Implicitement, il vous faut spécifier le typage des données, prévoir les assertions nécessaires, faire une approche la plus fonctionnelle possible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "https://docs.python.org/fr/3/library/heapq.html\n",
    "\n",
    "\"\"\"\n",
    "import heapq\n",
    "\n",
    "def test_heapq (dico:dict)->list:\n",
    "    tas=[]\n",
    "    for cle in dico:\n",
    "        heapq.heappush(tas,(dico[cle],cle))\n",
    "    while tas:\n",
    "        valeur=heapq.heappop(tas)\n",
    "        print(f'La plus petite valeur du tas était : {valeur}, tas : {tas}')\n",
    "    return tas # vide\n",
    "\n",
    "# programme principal\n",
    "if __name__=='__main__':\n",
    "    lst1=['a','b','c','d','e']\n",
    "    lst2=[4,2,1,3,0]\n",
    "    dictionnaire={cle :valeur for cle, valeur in zip(lst1, lst2)}\n",
    "    lst_sortie_tas=test_heapq(dictionnaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sérialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rappel du format JSON\n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "exemple={\"musique\":\"rock\", \"nombre\":6, \"88\":\"bidon\", \"liste\":[1,5,8], \"dico\":{\"cle\":\"valeur\"}, \"etat\":True}\n",
    "\n",
    "\n",
    "# Transforme mon dictionnaire en chaine de caractères\n",
    "chaine_json=json.dumps(exemple)\n",
    "\n",
    "print(chaine_json)\n",
    "print(type(chaine_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Désérialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rappel du format JSON\n",
    "\"\"\"\n",
    "import json\n",
    "\n",
    "dictionnaire=json.loads(chaine_json,encoding='utf-8')\n",
    "\n",
    "print(dictionnaire)\n",
    "print(type(dictionnaire))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pour aller plus loin\n",
    "\n",
    "Il faut être patient ...\n",
    "\"\"\"\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "urlretrieve('https://www.gutenberg.org/files/2650/2650-0.txt', 'swann.txt')\n",
    "file = open('swann.txt', 'r').read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
